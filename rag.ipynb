{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# User defined libraries\n",
    "from sitemap_crawler import get_urls_from_sitemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_urls_from_sitemap('https://jayeshmahapatra.github.io/sitemap.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load websites\n",
    "website_urls = get_urls_from_sitemap('https://jayeshmahapatra.github.io/sitemap.xml')\n",
    "loader = WebBaseLoader(website_urls)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators = [\"\\n\\n\", \"\\n\", \"\\\\[\", \"//]\", \"\\\\(\", '\\\\)',  \" \", \"\"]\n",
    "chunk_size = 512\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=int(chunk_size/10),\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=separators,\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"mistral:instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"<s> [INST] You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. [/INST] </s> \n",
    "[INST] Question: {input} \n",
    "Context: {context} \n",
    "Answer: [/INST]\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = retrieval_chain.invoke({\"input\": \"Why use arcface loss?\"})\n",
    "# print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:...\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RoPE embeddings are positional embeddings used in transformer models, applied after the self-attention mechanism. They are computed using the rotary position embedding function `apply_rotary_emb`, with cosine and sine frequencies generated by `precompute_freqs_cis` function. These embeddings help to capture relative positional information."
     ]
    }
   ],
   "source": [
    "query = \"What are RoPE embeddings?\"\n",
    "chunks = []\n",
    "metadata = []\n",
    "\n",
    "for chunk in retrieval_chain.stream({\"input\": query}):\n",
    "    if \"answer\" in chunk:\n",
    "        chunks.append(chunk)\n",
    "        print(chunk['answer'], end=\"\", flush=True)\n",
    "    else:\n",
    "        metadata.append(chunk)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'What are RoPE embeddings?'},\n",
       " {'context': [Document(page_content='# QKV\\n        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\\n        xq = xq.reshape(bsz, seqlen, self.n_local_heads, self.head_dim)\\n        xk = xk.reshape(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\\n        xv = xv.reshape(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\\n\\n        # RoPE relative positional embeddings\\n        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)', metadata={'source': 'https://jayeshmahapatra.github.io/2023/12/03/llama2.html', 'title': 'llama2.npy : Implementing Llama2 LLM using just Python and Numpy | Jayesh’s Blog', 'description': 'Large Language Models (LLMs), such as GPT-4, Claude, and Llama2, have reshaped the landscape of Natural Language Processing (NLP), democratizing AI applications. These models often have billions of parameters and are trained on massive datasets of text, often crawled from the internet.', 'language': 'en', 'start_index': 13577}),\n",
       "   Document(page_content='Embeddings & Separability\\nBefore we start discussing losses, let’s take a refresher on what embeddings are:', metadata={'source': 'https://jayeshmahapatra.github.io/2023/06/22/arcface.html', 'title': 'Enhancing Embedding Separation with ArcFace Loss | Jayesh’s Blog', 'description': 'Embeddings play a crucial role in Machine Learning by capturing and representing relationships between objects.', 'language': 'en', 'start_index': 806}),\n",
       "   Document(page_content='After this applying the softmax calculation and multiplying with value matrix as normal.\\n\\n\\nBelow is the python implementation of RoPE embeddings\\ndef precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\\n    freqs = 1.0 / (theta ** (np.arange(0, dim, 2)[: (dim // 2)].astype(np.float32) / dim))\\n    t = np.arange(end).astype(np.float32)\\n    freqs = np.outer(t, freqs).astype(np.float32)\\n    freqs_cos = np.cos(freqs)\\n    freqs_sin = np.sin(freqs)\\n    return freqs_cos, freqs_sin', metadata={'source': 'https://jayeshmahapatra.github.io/2023/12/03/llama2.html', 'title': 'llama2.npy : Implementing Llama2 LLM using just Python and Numpy | Jayesh’s Blog', 'description': 'Large Language Models (LLMs), such as GPT-4, Claude, and Llama2, have reshaped the landscape of Natural Language Processing (NLP), democratizing AI applications. These models often have billions of parameters and are trained on massive datasets of text, often crawled from the internet.', 'language': 'en', 'start_index': 17519}),\n",
       "   Document(page_content='Embeddings play a crucial role in Machine Learning by capturing and representing relationships between objects.\\nEmbeddings can be obtained from Neural Networks trained with traditional classification losses. However, these losses do not explicitly optimize cosine distances to achieve both inter-class separability and intra-class compactness.', metadata={'source': 'https://jayeshmahapatra.github.io/2023/06/22/arcface.html', 'title': 'Enhancing Embedding Separation with ArcFace Loss | Jayesh’s Blog', 'description': 'Embeddings play a crucial role in Machine Learning by capturing and representing relationships between objects.', 'language': 'en', 'start_index': 257})]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from constants import CHROMA_DOCS_INDEX_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Chroma client and vectorstore\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Chroma schema if it does not exist\n",
    "collection = chroma_client.get_or_create_collection(CHROMA_DOCS_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_data = collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'data', 'uris'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
